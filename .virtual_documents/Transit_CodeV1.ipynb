


import requests
import json
import pandas as pd
import matplotlib.pyplot as plt
import numpy as np

import missingno as msno

from bokeh.models import ColumnDataSource, GMapOptions
from bokeh.plotting import gmap, show



plt.style.use('ggplot')
# setting viewing options so can inspect all rows or columns without "..."
pd.set_option('display.max_rows', 500)
pd.set_option('display.max_columns', 500)
pd.set_option('display.width', 1000)














# API Endpoint to the data
# https://data.cityofchicago.org/resource/85ca-t3if.json
# This uses API v2.1+ where $limit is unlimited, and the data is updated daily, so setting the limit to the total amount of rows shown on website at the time of notebook creation. 

# paging and limits are shown here ---> https://dev.socrata.com/docs/paging.html
response_API = requests.get("https://data.cityofchicago.org/resource/85ca-t3if.json?$limit=785112")
data_crashes = response_API.text

# default limit of 1000, used online for demo'ing
# response_API = requests.get("https://data.cityofchicago.org/resource/85ca-t3if.json")


crashDF = pd.read_json(data_crashes)
crashDF.head()


crashDF.info()





# Use API to get all the data and put it into a new DF.
response_API = requests.get("https://data.cityofchicago.org/resource/68nd-jvt3.json?$limit=1524885")
data_vehicles = response_API.text

vehiclesDF = pd.read_json(data_vehicles)
vehiclesDF.head()





crashDF.info()


crashDF.isna().sum()





covrt_toDT = ["date_police_notified","crash_date"]

for x in covrt_toDT:
    temp = pd.to_datetime(crashDF[x])
    crashDF[x] = temp


crashDF.date_police_notified.head()





msno.matrix(crashDF)





colsListToDrop = crashDF.columns[crashDF.isna().sum() > 5600].to_list()
crashDF.drop(colsListToDrop, axis=1, inplace=True)
crashDF.head()


crashDF.shape


crashDF.isna().sum()





crashDF.dropna(subset=["street_direction","street_name","beat_of_occurrence", "latitude", "longitude","location"], inplace=True)


crashDF.injuries_total.value_counts()


crashDF.injuries_incapacitating.value_counts(), crashDF.injuries_reported_not_evident.value_counts(), 





crashDF.fillna(0, inplace=True)
crashDF.isna().sum()


crashDF.shape





# How much of what is missing from the data?
vehiclesDF.isna().sum()





# https://github.com/ResidentMario/missingno
msno.matrix(vehiclesDF)





vehiclesDF.columns[vehiclesDF.isna().sum() > 50000].to_list()


# number picked to separate the mostly empty from the others
threshMASK = vehiclesDF.isna().sum() > 50000

colsListToDrop = vehiclesDF.columns[threshMASK].to_list()


# Checking the format is what is needed
print(colsListToDrop, "\n", type(colsListToDrop))


vehiclesDF.drop(colsListToDrop, axis=1, inplace=True)


vehiclesDF.isna().sum()


# We are going to drop the remaining 35K missing values.
vehiclesDF.dropna(inplace=True)
vehiclesDF.isna().sum()


# Quick look to see how many records we have after dropping the NA values.
vehiclesDF.info()


# Fixing data types
# making int first to remove the floating zero, then strings
temp = vehiclesDF["vehicle_id"].astype(int)
vehiclesDF["vehicle_id"] = temp.astype(str)





# Stand in variables for both DF. I plan to work on smaller slices verifying it the joins work as expected.
dummyVEH = vehiclesDF.head(50)
dummyCRA = crashDF.head(50)


dummyVEH.shape, dummyCRA.shape





# grouping by ID then joining the individual vehicle IDs. The len(vehicle_use[n]) == total vehicles detailed in the report.
part1 = dummyVEH.groupby("crash_record_id")['vehicle_id'].apply(', '.join).reset_index()


# Getting the type of use, includes "CTA".
part2 = dummyVEH.groupby("crash_record_id")['vehicle_use'].apply(', '.join).reset_index()

part3 = dummyVEH.groupby("crash_record_id")['make'].apply(', '.join).reset_index()


dummyVEH_new = pd.merge(part1, part2, on="crash_record_id")
dummyVEH_new = pd.merge(dummyVEH_new, part3, on="crash_record_id")


dummyVEH_new.head()


dummyVEH_new.shape





dummyNEW = pd.merge(dummyCRA, dummyVEH_new, on="crash_record_id")
dummyNEW.info()


dummyNEW.shape





# grouping by ID then joining the individual vehicle IDs. The len(vehicle_use[n]) == total vehicles detailed in the report.
part1 = vehiclesDF.groupby("crash_record_id")['vehicle_id'].apply(', '.join).reset_index()
part2 = vehiclesDF.groupby("crash_record_id")['vehicle_use'].apply(', '.join).reset_index()
part3 = vehiclesDF.groupby("crash_record_id")['make'].apply(', '.join).reset_index()


fullVEH = pd.merge(part1, part2, on="crash_record_id")
fullVEH = pd.merge(fullVEH, part3, on="crash_record_id")


fullVEH.shape


finalDF = pd.merge(crashDF, fullVEH, on="crash_record_id")
finalDF.shape


#Resetting the index because it is good pratice
finalDF.reset_index(inplace=True, drop=True)


finalDF.info()


print(f"The difference between the joined data frames is {crashDF.shape[0] - finalDF.shape[0]} rows.")








# Dictionary to keep all the dataframes together.
dateDict = {
"Y14": 2014,
"Y15": 2015,
"Y16": 2016,
"Y17": 2017,
"Y18": 2018,
"Y19": 2019,
"Y20": 2020,
"Y21": 2021,
"Y22": 2022,
"Y23": 2023
}


# Used for labeling and series purpose.
years = [
    2014,
    2015,
    2016,
    2017,
    2018,
    2019,
    2020,
    2021,
    2022,
    2023
]


finalDF.crash_date.dt.year


# Looping through the dataDict, using the value as the YEAR mask    
crashDict = {}

for k, v in dateDict.items():
    tempVarName = k + "_crashes"
    crashDict[tempVarName] = finalDF[finalDF.crash_date.dt.year == v]
    print(f"{tempVarName} is a new dataframe. So start exploring!")


# Only records that contain "CTA" in the vehicle_use.
ctaDict = {}

for k, v in crashDict.items():
    CTAdfmask = crashDict[k][crashDict[k]["vehicle_use"].str.contains("CTA")]
    ctaDict[k] = CTAdfmask



ctaDict["Y20_crashes"].info()


# Total records per year
totalRecords = [crashDict[x]["crash_record_id"].count() for x in crashDict.keys()]
[print(f"There are {x} records for calendar year {y}") for x, y in zip(totalRecords, years)]





del crashDict["Y14_crashes"]
del crashDict["Y15_crashes"]





fig, ax = plt.subplots()
ax.bar([str(x) for x in years], totalRecords, label=[str(x) for x in years], color="#009DDC")

# Making it prettier. Titles, ticks, etc
ax.set_title("Total reports of crashes by year")
ax.set_xlabel("Year")


new = years[4:]


totalRecords








#Using the built in describe to give us basic statistics about numeric values. Day and Time are also going to be included, and time is in 24hr format, so will effect results of this
templist = []

for k, v in crashDict.items():
    this = crashDict[k].describe()[1:2][["posted_speed_limit","num_units", "crash_hour", "crash_day_of_week"]]
    this["year"] = k
    templist.append(this)



templist





#Using the built in describe to give us basic statistics about numeric values. Day and Time are also going to be included, and time is in 24hr format, so will effect results of this
templistCTA = []

for k, v in crashDict.items():
    CTAdfmask = crashDict[k][crashDict[k]["vehicle_use"].str.contains("CTA")]
    
    this = CTAdfmask.describe()[1:2][["posted_speed_limit","num_units", "crash_hour", "crash_day_of_week"]]
    this["year"] = k
    templistCTA.append(this)



templistCTA








#Using the built in describe to give us basic statistics about numeric values. Day and Time are also going to be included, and time is in 24hr format, so will effect results of this
quantofCTA = []

for k, v in crashDict.items():
    CTAdfmask = crashDict[k][crashDict[k]["vehicle_use"].str.contains("CTA")]
    this = CTAdfmask.shape[0]
    that = crashDict[k].shape[0]
    # appending a list in a list, for quick DF
    quantofCTA.append([this, that, k])



quantofCTA


perctDF = pd.DataFrame(quantofCTA, columns=["involves_cta", "all_crashes", "year"])
perctDF





perctDF["perct_cta"] = perctDF["involves_cta"]/perctDF["all_crashes"]


perctDF


plt.bar(x="year", height="involves_cta", data=perctDF)
plt.xticks(rotation=35)
plt.title("Total Incidents involving the CTA")








#Using the built in describe to give us basic statistics about numeric values. Day and Time are also going to be included, and time is in 24hr format, so will effect results of this
ctaDict = {}

for k, v in crashDict.items():
    CTAdfmask = crashDict[k][crashDict[k]["vehicle_use"].str.contains("CTA")]
    # appending a list in a list, for quick DF
    ctaDict[k] = CTAdfmask



# The party responsible is going to be in column 0 in this case.
# For YEar X CTA was indicated as the at fault party X amount of times
ctaDict["Y22_crashes"]["vehicle_use"].str.split(",", expand=True)


temp = ctaDict["Y22_crashes"]["vehicle_use"].str.split(",", expand=True)
# Total true (1) values in 1st column.
temp[0].str.contains("CTA").sum()


# Lets make loop to get all these values and the append it to the perctDF
at_faultList = []

for k, v in ctaDict.items():
    tempdf = ctaDict[k]["vehicle_use"].str.split(",", expand=True)
    placeholder = tempdf[0].str.contains("CTA").sum()
    at_faultList.append(placeholder)

at_faultList


# Lets make loop to get all these values and the append it to the perctDF
# Also lets remove those we are unable to determine
at_faultList = []

for k, v in ctaDict.items():
    tempdf = ctaDict[k][ctaDict[k].prim_contributory_cause == "UNABLE TO DETERMINE"]
    tempdf2 = tempdf["vehicle_use"].str.split(",", expand=True)
    placeholder = tempdf2[0].str.contains("CTA").sum()
    at_faultList.append(placeholder)

at_faultList


perctDF["cta_1st"] = at_faultList


perctDF["percAtFault"] = perctDF["cta_1st"]/perctDF["involves_cta"]


perctDF








ctaDict["Y19_crashes"].prim_contributory_cause.value_counts(normalize=True)



ctaDict["Y20_crashes"].prim_contributory_cause.value_counts(normalize=True)



ctaDict["Y21_crashes"].prim_contributory_cause.value_counts(normalize=True)



ctaDict["Y22_crashes"].prim_contributory_cause.value_counts(normalize=True)


ctaDict["Y23_crashes"].prim_contributory_cause.value_counts(normalize=True)





#Loop through and count instances if they contain.

for k, v in ctaDict.items():
    tempCountBus = ctaDict[k]["make"].str.contains("NOVA BUS")
    totalBus = tempCountBus.sum()


    tempCountFlyer = ctaDict[k]["make"].str.contains("NEW FLYER")
    totalFlyer = tempCountFlyer.sum()


    tempCountTrans = ctaDict[k]["make"].str.contains("TRANSIT")
    totalTrans = tempCountTrans.sum()

    
    print(f"{k} there were {totalBus} NOVA BUS")
    print(f"{k} there were {totalFlyer} NEW FLYER")
    print(f"{k} there were {totalTrans} TRANSIT")


 temp = ctaDict["Y20_crashes"]["make"].str.contains("NOVA BUS|NEW FLYER|TRANSIT")
temp.sum()





tempDF = ctaDict["Y20_crashes"]["make"].str.split(",", expand=True)
tempDF[0].value_counts(), tempDF[1].value_counts()


ctaDict["Y23_crashes"].head()





weekDays = ("Monday","Tuesday","Wednesday","Thursday","Friday","Saturday","Sunday")


crashDict.keys()


# day of week (dow) dictionary
dowDict = {}
yearsWeWant = ["Y21_crashes", "Y22_crashes", "Y23_crashes"]

for k, v in crashDict.items():
    if k not in yearsWeWant:
        pass
    else:
        data = crashDict[k].groupby("crash_day_of_week").count()["crash_record_id"]
        dowDict[k] = data


dowDict


redLine = "#E33719"
blueLine = "#009DDC"
brownLine = "#764200"
greenLine = "#00A94F"
orangeLine = "#E07836"


fig, ax = plt.subplots(1,3, figsize=(13, 6), sharex=True, sharey=True)
plt.xticks(rotation=35)
counter = 0
toColor = [redLine, blueLine, greenLine]

for k, v in dowDict.items():
    # Resolving legend issues. Had to put "_nolegend_" on the other lines
    if counter == 0:
        ax[counter].bar(x=weekDays, height=v, color=toColor[counter], label=k)
        ax[counter].tick_params(labelrotation=45)
        ax[counter].axhline(y=16000, xmin=0, c="black", linewidth=.8, zorder=0, label="16,000")

    else:
        ax[counter].bar(x=weekDays, height=v, color=toColor[counter], label=k)
        ax[counter].tick_params(labelrotation=45)
        ax[counter].axhline(y=16000, xmin=0, c="black", linewidth=.8, zorder=0, label="_nolegend_")

    
    counter += 1

fig.suptitle("Traffic Crashes on City Streets, by day of the week")
fig.legend(bbox_to_anchor=(1.0, .93), loc='upper left')
fig.tight_layout()


# Blue Line Color #009DDC

# https://www.transitchicago.com/developers/branding/#branding


crashDF.head()

















from scipy.stats import chisquare


# day of week (dow) dictionary
yearsWeWant = ["Y21_crashes", "Y22_crashes", "Y23_crashes"]

for k, v in dowDict.items():
    if k in yearsWeWant:
        chi2_stat, p_val = chisquare(v)

        # Display the results
        print(f"{k}")
        print(f"Chi2 Stat: {chi2_stat}")
        print(f"P-value: {p_val}")
        print("\n")
    else:
        pass








ctaDict["Y20_crashes"][ctaDict["Y20_crashes"]["crash_day_of_week"] == 1]


# values I want. Now groupby dow and plot them
ctaDict["Y20_crashes"].crash_date.dt.hour


ctaDict["Y20_crashes"].columns


ctaDict["Y20_crashes"]["timeOFday"] = ctaDict["Y20_crashes"].crash_date.dt.time


temp = ctaDict["Y20_crashes"].groupby(["crash_day_of_week", "timeOFday"]).count()


temp.head()











ctaDict["Y22_crashes"][["longitude", "latitude"]]


# Creating lat and long dicts for '22 as a tester.

latList = ctaDict["Y22_crashes"]["latitude"].to_list()
lonList = ctaDict["Y22_crashes"]["longitude"].to_list()

source = ColumnDataSource(
    data=dict(lat=latList,
              lon=lonList),
)



map_options = GMapOptions(lat=41.885300, lng=-87.642320, map_type="roadmap", zoom=13)

# For GMaps to function, Google requires you obtain and enable an API key:
#
#     https://developers.google.com/maps/documentation/javascript/get-api-key
#
# Replace the value below with your personal API key:
p = gmap("AIzaSyCEC95GOkQ0C9tp3JuoRHFmUkBnJCOaNmU", map_options, title="Chicago")

p.circle(x="lon", y="lat", size=4, fill_color="red", fill_alpha=0.8, source=source)

show(p)





# Creating lat and long dicts for
for k,v in ctaDict.items():
    latList = ctaDict[k]["latitude"].to_list()
    lonList = ctaDict[k]["longitude"].to_list()
    
    source = ColumnDataSource(
        data=dict(lat=latList,
                  lon=lonList),
    )
    
    
    map_options = GMapOptions(lat=41.885300, lng=-87.642320, map_type="roadmap", zoom=13)
    
    p = gmap("", map_options, title=f"Chicago {k}")
    
    
    p.circle(x="lon", y="lat", size=4, fill_color="red", fill_alpha=0.8, source=source)
    
    show(p)








whereAreTheseDict = {}

for k, v in ctaDict.items():
    CTAdfmask = ctaDict[k][ctaDict[k].prim_contributory_cause == "UNABLE TO DETERMINE"]
    # appending a list in a list, for quick DF
    whereAreTheseDict[k] = CTAdfmask



whereAreTheseDict.keys()

del whereAreTheseDict["Y16_crashes"]
del whereAreTheseDict["Y17_crashes"]
del whereAreTheseDict["Y18_crashes"]
del whereAreTheseDict["Y19_crashes"]
del whereAreTheseDict["Y20_crashes"]

whereAreTheseDict.keys()


# Creating lat and long dicts for
for k,v in whereAreTheseDict.items():
    latList = whereAreTheseDict[k]["latitude"].to_list()
    lonList = whereAreTheseDict[k]["longitude"].to_list()
    
    source = ColumnDataSource(
        data=dict(lat=latList,
                  lon=lonList),
    )
    
    
    map_options = GMapOptions(lat=41.885300, lng=-87.642320, map_type="roadmap", zoom=13)
    
    p = gmap("", map_options, title=f"CTA Incidents where cause is Unknown {k}")
    
    
    p.circle(x="lon", y="lat", size=4, fill_color="red", fill_alpha=0.8, source=source)
    
    show(p)


# This is everyone. I need to break it out into days of the week 1st
fig, axs = plt.subplots(figsize=(12, 4))

whereAreTheseDict["Y21_crashes"].groupby(whereAreTheseDict["Y21_crashes"].crash_date.dt.hour)["make"].count().plot(
    kind='bar', rot=0, ax=axs
)
plt.title("Number of Incidents Involving the CTA with Cause Undetermined - Y21")
plt.xlabel("Hour - 24hr")
plt.savefig("Number of Incidents Involving the CTA with Cause Undetermined - Y21", format="png")


# This is everyone. I need to break it out into days of the week 1st
fig, axs = plt.subplots(figsize=(12, 4))

whereAreTheseDict["Y22_crashes"].groupby(whereAreTheseDict["Y22_crashes"].crash_date.dt.hour)["make"].count().plot(
    kind='bar', rot=0, ax=axs
)
plt.title("Number of Incidents Involving the CTA with Cause Undetermined - Y22")
plt.xlabel("Hour - 24hr")
plt.savefig("Number of Incidents Involving the CTA with Cause Undetermined - Y22", format="png")


# This is everyone. I need to break it out into days of the week 1st
fig, axs = plt.subplots(figsize=(12, 4))

whereAreTheseDict["Y23_crashes"].groupby(whereAreTheseDict["Y23_crashes"].crash_date.dt.hour)["make"].count().plot(
    kind='bar', rot=0, ax=axs
)

plt.title("Number of Incidents Involving the CTA with Cause Undetermined - Y23")
plt.xlabel("Hour - 24hr")
plt.savefig("Number of Incidents Involving the CTA with Cause Undetermined - Y23", format="png")





whereAreTheseDict["Y23_crashes"].first_crash_type.value_counts(normalize=True)


whereAreTheseDict["Y22_crashes"].first_crash_type.value_counts(normalize=True)


whereAreTheseDict["Y21_crashes"].first_crash_type.value_counts(normalize=True)


whereAreTheseDict["Y21_crashes"].shape


whereAreTheseDict["Y22_crashes"].shape


whereAreTheseDict["Y23_crashes"].shape





whereAreTheseDict["Y23_crashes"].groupby(whereAreTheseDict["Y23_crashes"].crash_date.dt.hour).count()






